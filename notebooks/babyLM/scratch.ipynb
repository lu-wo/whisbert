{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "def create_audio_alignment_mapping(audio_root: str, alignment_root: str):\n",
    "    found = 0\n",
    "    not_found = 0\n",
    "    mapping = []\n",
    "\n",
    "    # Get all .flac files in the audio_root directory\n",
    "    audio_files = glob.glob(f\"{audio_root}/**/*.flac\", recursive=True)\n",
    "\n",
    "    for audio_file in audio_files:\n",
    "        # Get the name of the file without the extension\n",
    "        name = os.path.basename(audio_file).rsplit(\".\", 1)[0]\n",
    "\n",
    "        # Construct the path to the expected alignment directory\n",
    "        alignment_dir = os.path.join(alignment_root, name)\n",
    "\n",
    "        # Check if the alignment directory exists\n",
    "        if os.path.isdir(alignment_dir):\n",
    "            # Get the transcript file in the alignment directory\n",
    "            transcript_files = glob.glob(f\"{alignment_dir}/*.txt\")\n",
    "            if transcript_files:\n",
    "                # Append the audio file and transcript file to the mapping\n",
    "                mapping.append(dict(audio=audio_file, transcript=transcript_files[0]))\n",
    "                # ((audio_file, transcript_files[0]))\n",
    "                found += 1\n",
    "            else:\n",
    "                not_found += 1\n",
    "        else:\n",
    "            not_found += 1\n",
    "\n",
    "    print(f\"Found: {found}\")\n",
    "    print(f\"Not found: {not_found}\")\n",
    "\n",
    "    return mapping\n",
    "\n",
    "\n",
    "# Uncomment the next line and replace the paths to test the function\n",
    "# create_audio_alignment_mapping(\"path/to/audio/root\", \"path/to/alignment/root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 2\n",
      "Not found: 3\n"
     ]
    }
   ],
   "source": [
    "audio_root = \"/Users/lukas/Desktop/Projects/MIT/data/peoples_speech/audio_debug\"\n",
    "alignment_root = (\n",
    "    \"/Users/lukas/Desktop/Projects/MIT/data/peoples_speech/peoples-speech-clean\"\n",
    ")\n",
    "\n",
    "mapping = create_audio_alignment_mapping(audio_root, alignment_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'audio': '/Users/lukas/Desktop/Projects/MIT/data/peoples_speech/audio_debug/1_2_2018_Williston_Selectboard_SLASH_1_2_2018_Williston_Selectboard_DOT_mp3/1_2_2018_Williston_Selectboard_SLASH_1_2_2018_Williston_Selectboard_DOT_mp3.flac',\n",
       "  'transcript': '/Users/lukas/Desktop/Projects/MIT/data/peoples_speech/peoples-speech-clean/1_2_2018_Williston_Selectboard_SLASH_1_2_2018_Williston_Selectboard_DOT_mp3/1_2_2018_Williston_Selectboard_SLASH_1_2_2018_Williston_Selectboard_DOT_mp3_transcript.txt'},\n",
       " {'audio': '/Users/lukas/Desktop/Projects/MIT/data/peoples_speech/audio_debug/1_2_2018_Winooski_City_Council_SLASH_1_2_2018_Winooski_City_Council_DOT_mp3/1_2_2018_Winooski_City_Council_SLASH_1_2_2018_Winooski_City_Council_DOT_mp3.flac',\n",
       "  'transcript': '/Users/lukas/Desktop/Projects/MIT/data/peoples_speech/peoples-speech-clean/1_2_2018_Winooski_City_Council_SLASH_1_2_2018_Winooski_City_Council_DOT_mp3/1_2_2018_Winooski_City_Council_SLASH_1_2_2018_Winooski_City_Council_DOT_mp3_transcript.txt'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/prosody/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# load bert tokenizer\n",
    "\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = 101\n",
    "\n",
    "tokenizer.convert_ids_to_tokens(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 79])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t = torch.tensor(\n",
    "    [\n",
    "        [\n",
    "            -100,\n",
    "            3432,\n",
    "            2517,\n",
    "            -100,\n",
    "            8910,\n",
    "            -100,\n",
    "            1996,\n",
    "            -100,\n",
    "            2030,\n",
    "            12381,\n",
    "            2714,\n",
    "            2653,\n",
    "            -100,\n",
    "            1037,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            2852,\n",
    "            -100,\n",
    "            -100,\n",
    "            1005,\n",
    "            1055,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            6767,\n",
    "            -100,\n",
    "            -100,\n",
    "            6588,\n",
    "            6366,\n",
    "            -100,\n",
    "            1012,\n",
    "            11338,\n",
    "            -100,\n",
    "            2271,\n",
    "            -100,\n",
    "            -100,\n",
    "            3218,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            1012,\n",
    "            1999,\n",
    "            -100,\n",
    "            -100,\n",
    "            2008,\n",
    "            2852,\n",
    "            1012,\n",
    "            9712,\n",
    "            17912,\n",
    "            27161,\n",
    "            2000,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            7559,\n",
    "            -100,\n",
    "            4487,\n",
    "            20939,\n",
    "            -100,\n",
    "            7405,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            2271,\n",
    "            -100,\n",
    "            -100,\n",
    "            1012,\n",
    "            -100,\n",
    "            -100,\n",
    "            1996,\n",
    "            -100,\n",
    "            2106,\n",
    "            102,\n",
    "        ],\n",
    "        [\n",
    "            -100,\n",
    "            2025,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            1998,\n",
    "            4487,\n",
    "            -100,\n",
    "            6499,\n",
    "            -100,\n",
    "            8910,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            1010,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            2031,\n",
    "            2589,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            1996,\n",
    "            -100,\n",
    "            2653,\n",
    "            -100,\n",
    "            -100,\n",
    "            2122,\n",
    "            -100,\n",
    "            3033,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            2595,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            3832,\n",
    "            -100,\n",
    "            3115,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            11338,\n",
    "            2386,\n",
    "            2271,\n",
    "            -100,\n",
    "            2852,\n",
    "            -100,\n",
    "            9712,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            2852,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "            -100,\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 79, 30522])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = torch.rand(2, t.shape[1], 30522)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.3751)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-100)\n",
    "loss = loss_fct(pred.view(-1, 30522), t.view(-1))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.3751)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ignore_indices = t == -100\n",
    "\n",
    "valid_t = t[~ignore_indices]\n",
    "valid_pred = pred[~ignore_indices]\n",
    "\n",
    "loss_fct(valid_pred.view(-1, 30522), valid_t.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prosody",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
