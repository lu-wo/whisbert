{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/prosody/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers.models.wav2vec2.modeling_wav2vec2 import (\n",
    "    _compute_mask_indices,\n",
    "    _sample_negative_indices,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, seqlen, feat = 16, 100, 78\n",
    "\n",
    "preds = torch.rand(bs, seqlen, feat)\n",
    "labels = torch.rand(bs, seqlen, feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_time_indices = _compute_mask_indices(\n",
    "    shape=(bs, seqlen), mask_prob=0.5, mask_length=1\n",
    ")\n",
    "mask_time_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 100, 20])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_negative_indices = _sample_negative_indices(\n",
    "    features_shape=(bs, seqlen),\n",
    "    num_negatives=20,\n",
    "    mask_time_indices=mask_time_indices,\n",
    ")\n",
    "sampled_negative_indices = torch.from_numpy(sampled_negative_indices)\n",
    "sampled_negative_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32000, 78])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 16, 100, 78])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for training, we sample negatives\n",
    "# 3. sample K negatives (distractors) quantized states for contrastive loss\n",
    "\n",
    "negative_features = labels.view(-1, feat)[sampled_negative_indices.long().view(-1)]\n",
    "print(negative_features.shape)\n",
    "\n",
    "negative_features = negative_features.view(bs, seqlen, -1, feat).permute(2, 0, 1, 3)\n",
    "negative_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_contrastive_logits(\n",
    "    target_features: torch.FloatTensor,\n",
    "    negative_features: torch.FloatTensor,\n",
    "    predicted_features: torch.FloatTensor,\n",
    "    temperature: int = 0.1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute logits for contrastive loss based using cosine similarity as the distance measure between\n",
    "    `[positive_feature, negative_features]` and `[predicted_features]`. Additionally, temperature can be applied.\n",
    "    \"\"\"\n",
    "    target_features = torch.cat([target_features, negative_features], dim=0)\n",
    "\n",
    "    logits = torch.cosine_similarity(\n",
    "        predicted_features.float(), target_features.float(), dim=-1\n",
    "    ).type_as(target_features)\n",
    "\n",
    "    # apply temperature\n",
    "    logits = logits / temperature\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 16, 100])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. compute logits, corresponding to `logs = sim(c_t, [q_t, \\sim{q}_t]) / \\kappa`\n",
    "# of equation (3) in https://arxiv.org/pdf/2006.11477.pdf\n",
    "\n",
    "logits = compute_contrastive_logits(labels[None, :], negative_features, preds)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 16, 100])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. if a negative vector is identical to the positive (i.e. when codebook utilization is low),\n",
    "# its cosine similarity will be masked\n",
    "\n",
    "neg_is_pos = (preds == negative_features).all(-1)\n",
    "neg_is_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if neg_is_pos.any():\n",
    "    logits[1:, neg_is_pos] = float(\"-inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 16, 100])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1600, 21]), torch.Size([1600]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. compute contrastive loss \\mathbf{L}_m = cross_entropy(logs) =\n",
    "# -log(exp(sim(c_t, q_t)/\\kappa) / \\sum_{\\sim{q}} exp(sim(c_t, \\sim{q})/\\kappa))\n",
    "mask_time_indices = torch.from_numpy(mask_time_indices)\n",
    "\n",
    "logits = logits.transpose(0, 2).reshape(-1, logits.size(0))\n",
    "target = ((1 - mask_time_indices.long()) * -100).transpose(0, 1).flatten()\n",
    "logits.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0946)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrastive_loss = nn.functional.cross_entropy(logits.float(), target, reduction=\"mean\")\n",
    "contrastive_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: torch.Size([16, 100, 78]), torch.Size([16, 100, 78]), (16, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3.0854, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers.models.wav2vec2.modeling_wav2vec2 import (\n",
    "    _compute_mask_indices,\n",
    "    _sample_negative_indices,\n",
    ")\n",
    "from src.utils.torch_utils import Wav2Vec2ContrastiveLoss\n",
    "\n",
    "\n",
    "# Test the class\n",
    "preds = torch.rand(bs, seqlen, feat).requires_grad_(True)\n",
    "labels = torch.rand(bs, seqlen, feat)\n",
    "loss_fn = Wav2Vec2ContrastiveLoss(mask_rate=0.5, reduction=\"mean\")\n",
    "mask = loss_fn.create_mask((bs, seqlen))\n",
    "print(f\"shapes: {preds.shape}, {labels.shape}, {mask.shape}\")\n",
    "loss = loss_fn(preds, labels, mask)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t = torch.arange(10)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prosody",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
