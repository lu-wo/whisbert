{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/prosody/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from src.models.components.lstm_autoencoder import LSTMAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm enc out shape: torch.Size([16, 100, 128])\n",
      "fc enc out shape: torch.Size([16, 100, 64])\n",
      "fc dec out shape: torch.Size([16, 100, 128])\n",
      "lstm dec out shape: torch.Size([16, 100, 1])\n"
     ]
    }
   ],
   "source": [
    "lstm_enc = torch.nn.LSTM(1, 128, 3, batch_first=True)\n",
    "fc_enc = torch.nn.Linear(128, 64)\n",
    "fc_dec = torch.nn.Linear(64, 128)\n",
    "lstm_dec = torch.nn.LSTM(128, 1, 3, batch_first=True)\n",
    "\n",
    "t = torch.randn(16, 100, 1)\n",
    "out, _ = lstm_enc(t)\n",
    "print(\"lstm enc out shape:\", out.shape)\n",
    "out = fc_enc(out)\n",
    "print(\"fc enc out shape:\", out.shape)\n",
    "out = fc_dec(out)\n",
    "print(\"fc dec out shape:\", out.shape)\n",
    "out, _ = lstm_dec(out)\n",
    "print(\"lstm dec out shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([8, 100, 1])\n",
      "Original time-series shape: torch.Size([8, 100, 1])\n",
      "Reconstructed time-series shape: torch.Size([8, 100, 1])\n",
      "Encoding shape: torch.Size([8, 100, 128])\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_size = 1  # Number of input features\n",
    "hidden_size = 256  # Hidden units in LSTM layers\n",
    "latent_size = 128  # Size of the fixed-size representation\n",
    "num_layers = 1  # Number of LSTM layers\n",
    "dropout = 0.0  # Dropout probability\n",
    "\n",
    "# Create the LSTM autoencoder\n",
    "model = LSTMAutoencoder(input_size, hidden_size, latent_size, num_layers, dropout)\n",
    "\n",
    "# input params\n",
    "bs = 8\n",
    "seq_len = 100\n",
    "n_features = 1\n",
    "\n",
    "# Example usage\n",
    "time_series = torch.randn(\n",
    "    bs, seq_len, n_features\n",
    ")  # 8 time-series samples, each of length 100 and with 1 feature\n",
    "reconstructed_time_series, encoding = model(time_series)\n",
    "\n",
    "print(\"Original time-series shape:\", time_series.shape)\n",
    "print(\"Reconstructed time-series shape:\", reconstructed_time_series.shape)\n",
    "print(\"Encoding shape:\", encoding.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/lukas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/lukas/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from src.utils.old_features import (\n",
    "    get_features_from_lab_root,\n",
    "    F0Extractor,\n",
    "    read_lab_file,\n",
    "    get_features_from_lab_wav_path,\n",
    "    get_features_from_lab_root,\n",
    ")\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "from src.utils.prosody_tools.f0_processing import _interpolate\n",
    "from src.data.components.feature_extractors import LibriTTSFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WAV_PATH = \"/Users/lukas/Desktop/projects/MIT/data/LibriTTS/debug/237/126133/237_126133_000001_000000.wav\"\n",
    "LAB_PATH = \"/Users/lukas/Desktop/projects/MIT/data/LibriTTSCorpusLabel/debug/237/126133/237_126133_000001_000000.lab\"\n",
    "LAB_ROOT = \"/Users/lukas/Desktop/projects/MIT/data/LibriTTSCorpusLabel/debug\"\n",
    "WAV_ROOT = \"/Users/lukas/Desktop/projects/MIT/data/LibriTTS/debug\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_extractor = F0Extractor(modes=[\"curve\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start extracting features from /Users/lukas/Desktop/projects/MIT/data/LibriTTSCorpusLabel/debug\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Readers: 100%|██████████| 1/1 [01:04<00:00, 64.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished extracting 99 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extractor = LibriTTSFeatureExtractor(\n",
    "    lab_root=LAB_ROOT,\n",
    "    wav_root=WAV_ROOT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curves = extractor.get_all_f0_curve()\n",
    "len(curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1683"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curves = [c for curve in curves for c in curve]\n",
    "len(curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, texts=None):\n",
    "        self.data = data\n",
    "        self.texts = texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sequence = torch.tensor(self.data[index], dtype=torch.float32)\n",
    "        if self.texts is not None:\n",
    "            text = self.texts[index]\n",
    "            return sequence, text\n",
    "        return sequence\n",
    "\n",
    "\n",
    "def rnn_collate_fn(batch, pad_value=-999):\n",
    "    sequences = [item for item in batch]\n",
    "    lengths = torch.tensor([len(seq) for seq in sequences])\n",
    "    padded_sequences = pad_sequence(\n",
    "        sequences, batch_first=True, padding_value=pad_value\n",
    "    )\n",
    "    mask = (padded_sequences != pad_value).float()  # Assuming 0 is your padding value\n",
    "    # unsqueeze(2) adds a dimension for the features\n",
    "    return padded_sequences.unsqueeze(2), lengths, mask.unsqueeze(2)\n",
    "    # return padded_sequences, lengths, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.676,  1.728,  1.715,  1.715,  1.715,  1.29 ,  1.29 ,  1.29 ,\n",
       "        1.264,  1.367,  1.367,  1.431,  1.483,  1.483,  1.509,  1.522,\n",
       "        1.522,  1.612,  1.625,  1.637, -0.435, -0.409, -0.396, -0.371,\n",
       "       -0.371, -0.371, -0.383, -0.383, -0.383, -0.371, -0.345, -0.345,\n",
       "       -0.358, -0.358, -0.358, -0.371, -0.396, -0.409, -0.409, -0.474,\n",
       "       -0.525, -0.589, -0.396, -0.396, -0.396, -0.383, -0.383, -0.383,\n",
       "       -0.396, -0.409, -0.435, -0.448, -0.461, -0.474, -0.474, -0.474,\n",
       "       -0.499, -0.512, -0.525, -0.538, -0.551, -0.564, -0.577, -0.602,\n",
       "       -0.602, -0.602, -0.602, -0.615, -0.615, -0.615, -0.615, -0.628,\n",
       "       -0.628, -0.641, -0.641, -0.641, -0.654, -0.654, -0.68 , -0.68 ,\n",
       "       -0.692, -0.731, -0.744, -0.808, -0.203, -0.126, -0.139, -0.1  ,\n",
       "        0.067,  0.08 ,  0.222,  0.157,  0.157])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curves[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TimeSeriesDataset(curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.6761,  1.7276,  1.7147,  1.7147,  1.7147,  1.2899,  1.2899,  1.2899,\n",
       "         1.2642,  1.3671,  1.3671,  1.4315,  1.4830,  1.4830,  1.5087,  1.5216,\n",
       "         1.5216,  1.6117,  1.6246,  1.6374, -0.4350, -0.4092, -0.3964, -0.3706,\n",
       "        -0.3706, -0.3706, -0.3835, -0.3835, -0.3835, -0.3706, -0.3449, -0.3449,\n",
       "        -0.3577, -0.3577, -0.3577, -0.3706, -0.3964, -0.4092, -0.4092, -0.4736,\n",
       "        -0.5251, -0.5894, -0.3964, -0.3964, -0.3964, -0.3835, -0.3835, -0.3835,\n",
       "        -0.3964, -0.4092, -0.4350, -0.4478, -0.4607, -0.4736, -0.4736, -0.4736,\n",
       "        -0.4993, -0.5122, -0.5251, -0.5380, -0.5508, -0.5637, -0.5766, -0.6023,\n",
       "        -0.6023, -0.6023, -0.6023, -0.6152, -0.6152, -0.6152, -0.6152, -0.6281,\n",
       "        -0.6281, -0.6409, -0.6409, -0.6409, -0.6538, -0.6538, -0.6795, -0.6795,\n",
       "        -0.6924, -0.7310, -0.7439, -0.8083, -0.2033, -0.1260, -0.1389, -0.1003,\n",
       "         0.0670,  0.0799,  0.2215,  0.1571,  0.1571])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2  # Adjust the batch size as needed\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=False, collate_fn=rnn_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded sequences shape: torch.Size([2, 93, 1])\n",
      "Lengths shape: torch.Size([2])\n",
      "Mask shape: torch.Size([2, 93])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    padded_sequences, lengths, mask = batch\n",
    "    print(\"Padded sequences shape:\", padded_sequences.shape)\n",
    "    # print(\"Padded sequences:\", padded_sequences)\n",
    "    print(\"Lengths shape:\", lengths.shape)\n",
    "    # print(\"Lengths:\", lengths)\n",
    "    print(\"Mask shape:\", mask.shape)\n",
    "    # print(\"Mask:\", mask)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prosody",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
